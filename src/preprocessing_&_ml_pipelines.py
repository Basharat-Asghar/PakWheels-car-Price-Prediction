# -*- coding: utf-8 -*-
"""Preprocessing & ML Pipelines.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nBSLwK3Ko7KOZb_tCzMpLVM6-BFezGyN

### Importing libraries
"""

import pandas as pd
import numpy as np
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import RobustScaler, OneHotEncoder, FunctionTransformer
from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor
from xgboost import XGBRegressor
import lightgbm as lgb
import joblib

import warnings
warnings.filterwarnings("ignore")

"""### Loading Data"""

df = pd.read_csv('https://raw.githubusercontent.com/Basharat-Asghar/PakWheels-car-Price-Prediction/refs/heads/main/data/cleaned_df.csv')

df.head()

"""#### Custom Transformer: Frequency Encoding"""

class FrequencyEncoder(BaseEstimator, TransformerMixin):
    def __init__(self):
      self.freq_maps = {}

    def fit(self, X, y=None):
      for col in X.columns:
          freqs = X[col].value_counts(normalize=True)
          self.freq_maps[col] = freqs
      return self

    def transform(self, X):
      X_encoded = X.copy()
      for col in X.columns:
          X_encoded[col] = X_encoded[col].map(self.freq_maps[col]).fillna(0)
      return X_encoded

"""#### Adding missingness flag"""

def add_missing_flags(df):
  df = df.copy()
  df['engine_cc_missing'] = df['engine_cc'].isna().astype(int)
  df['battery_kwh_missing'] = df['battery_kwh'].isna().astype(int)

  df['engine_cc'] = df['engine_cc'].fillna(0)
  df['battery_kwh'] = df['battery_kwh'].fillna(0)

  return df

missing_flagger = FunctionTransformer(add_missing_flags, validate=False)

num_features = ["year", "mileage_km", "engine_cc", "battery_kwh", "car_age", "boxcox_mileage", "engine_cc_missing", "battery_kwh_missing"]
cat_features = ["fuel", "transmission", "engine_type", "company"]
freq_features = ["model"]

"""Creating pipelines for scaling, frequency encoding, and one hot encoding."""

num_transformer = Pipeline(
    steps = [(
        "scaler", RobustScaler()
    )]
)

freq_transformer = Pipeline(
    steps = [(
        "freq", FrequencyEncoder()
    )]
)

onehot_transformer = Pipeline(
    steps = [(
        "onehot", OneHotEncoder(handle_unknown="ignore")
    )]
)

preprocessor = Pipeline(
    steps = [
        ("missing_flags", missing_flagger),
        ("transformers", ColumnTransformer(
            transformers = [
                ("num", num_transformer, num_features),
                ("freq", freq_transformer, freq_features),
                ("onehot", onehot_transformer, cat_features),
            ]
        ))
    ]
)

"""#### Splitting train, test data"""

X = df.drop(columns=["price_pkr_lacs"])
y = df['price_pkr_lacs']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42
)

def eval_model(pipeline, X_train, X_test, y_train, y_test):
  pipeline.fit(X_train, y_train)
  y_pred = pipeline.predict(X_test)

  mae = mean_absolute_error(y_test, y_pred)
  r2 = r2_score(y_test, y_pred)

  return {"Mean Absolute Error": mae, "R2 Score": r2}

"""#### Linear Regression Pipeline"""

lr_pipeline = Pipeline(
    steps = [
        ("preprocessor", preprocessor),
        ("regressor", LinearRegression())
    ]
)

lr_results = eval_model(lr_pipeline, X_train, X_test, y_train, y_test)

lr_results

"""#### Ridge Regression Pipeline"""

ridge_pipeline = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("regressor", Ridge(
        alpha=1.0,
        random_state=42
    ))
])

ridge_results = eval_model(ridge_pipeline, X_train, X_test, y_train, y_test)

ridge_results

"""#### Lasso Regression Pipeline"""

lasso_pipeline = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("regressor", Lasso(
        alpha=0.01,
        random_state=42,
        max_iter=10000
    ))
])

lasso_results = eval_model(lasso_pipeline, X_train, X_test, y_train, y_test)

lasso_results

"""#### ElasticNet Pipeline"""

elasticnet_pipeline = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("regressor", ElasticNet(
        alpha=0.1,        # overall regularization strength
        l1_ratio=0.5,     # mix between L1 and L2 (0=L2, 1=L1)
        random_state=42,
        max_iter=10000    # ensure convergence
    ))
])

elasticnet_results = eval_model(elasticnet_pipeline, X_train, X_test, y_train, y_test)

elasticnet_results

"""#### Decision Tree Pipeline"""

dt_pipeline = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("regressor", DecisionTreeRegressor(
        max_depth=10,       # limit depth to avoid overfitting
        min_samples_leaf=5, # prevent very small leaves
        random_state=42
    ))
])

dt_results = eval_model(dt_pipeline, X_train, X_test, y_train, y_test)

dt_results

"""#### Random Forest Pipeline"""

rf_pipeline = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("regressor", RandomForestRegressor(
        n_estimators=500,       # number of trees
        max_depth=15,           # limit depth to avoid overfitting
        min_samples_leaf=5,
        max_features="sqrt",    # features considered at each split
        n_jobs=-1,              # parallelize
        random_state=42
    ))
])

rf_results = eval_model(rf_pipeline, X_train, X_test, y_train, y_test)

rf_results

adaboost_pipeline = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("regressor", AdaBoostRegressor(
        estimator=DecisionTreeRegressor(max_depth=4),
        n_estimators=200,
        learning_rate=0.1,
        random_state=42
    ))
])

adaboost_results = eval_model(adaboost_pipeline, X_train, X_test, y_train, y_test)

adaboost_results

"""#### XGBoost Pipeline"""

xgb_pipeline = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("regressor", XGBRegressor(
        n_estimators=500,
        learning_rate=0.05,
        max_depth=6,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=42,
        n_jobs=-1
    ))
])

xgb_results = eval_model(xgb_pipeline, X_train, X_test, y_train, y_test)

xgb_results

"""#### LightGBM Pipeline"""

lgbm_pipeline = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("regressor", lgb.LGBMRegressor(
        n_estimators=500,
        learning_rate=0.05,
        max_depth=6,
        num_leaves=31,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=42,
        n_jobs=-1
    ))
])

lgbm_results = eval_model(lgbm_pipeline, X_train, X_test, y_train, y_test)

lgbm_results

"""#### LGBM Cross-Validation"""

mae_scores = -cross_val_score(
    lgbm_pipeline,
    X_train, y_train,
    cv=5,
    scoring='neg_mean_absolute_error',
    n_jobs=-1
)

r2_scores = cross_val_score(
    lgbm_pipeline,
    X_train, y_train,
    cv=5,
    scoring='r2',
    n_jobs=-1
)

print("Cross-validated MAE:", np.mean(mae_scores))
print("Cross-validated R2:", np.mean(r2_scores))

"""#### LGBM HyperParameter Tuning"""

param_grid = {
    "regressor__n_estimators": [300, 500, 700],
    "regressor__learning_rate": [0.01, 0.05, 0.1],
    "regressor__max_depth": [4, 6, 8],
    "regressor__num_leaves": [31, 50, 70],
    "regressor__subsample": [0.7, 0.8, 0.9],
    "regressor__colsample_bytree": [0.7, 0.8, 0.9]
}

random_search = RandomizedSearchCV(
    lgbm_pipeline,
    param_distributions=param_grid,
    n_iter=20,
    cv=3,
    scoring='r2',
    verbose=2,
    n_jobs=-1,
    random_state=42
)

random_search.fit(X_train, y_train)

print("Best Parameters:", random_search.best_params_)
print("Best CV R2:", random_search.best_score_)

"""#### Final LGBM Pipeline"""

final_lgbm_pipeline = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("regressor", lgb.LGBMRegressor(
        n_estimators=500,
        learning_rate=0.1,
        max_depth=8,
        num_leaves=31,
        subsample=0.7,
        colsample_bytree=0.8,
        random_state=42,
        n_jobs=-1
    ))
])

final_lgbm_results = eval_model(final_lgbm_pipeline, X_train, X_test, y_train, y_test)

final_lgbm_results

import joblib
joblib.dump(final_lgbm_pipeline, "lgbm_pipeline_final.pkl")