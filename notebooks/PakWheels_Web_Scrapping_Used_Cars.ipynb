{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPcjikxAsXZJ",
        "outputId": "08eb4a78-3cd8-471a-bb91-0d091bd0c183"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests beautifulsoup4 tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import random\n",
        "\n",
        "BASE_URL = \"https://www.pakwheels.com/used-cars/search/-/\"\n",
        "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "\n",
        "def scrape_page(page_num, retries=3, backoff=1):\n",
        "    \"\"\"\n",
        "    Scrapes one page of PakWheels listings with retry & exponential backoff.\n",
        "    \"\"\"\n",
        "    url = f\"{BASE_URL}?page={page_num}&_pjax=%5Bdata-pjax-container%5D\"\n",
        "\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            response = requests.get(url, headers=HEADERS, timeout=15)\n",
        "\n",
        "            if response.status_code != 200:\n",
        "                raise Exception(f\"HTTP {response.status_code}\")\n",
        "\n",
        "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "            listings = soup.find_all(\"li\", class_=\"classified-listing\")\n",
        "            page_data = []\n",
        "\n",
        "            for listing in listings:\n",
        "                try:\n",
        "                    # Title\n",
        "                    title_tag = listing.find(\"a\", class_=\"car-name ad-detail-path\")\n",
        "                    title = title_tag.get(\"title\") if title_tag else None\n",
        "\n",
        "                    # Price\n",
        "                    price_tag = listing.find(\"div\", class_=\"price-details generic-dark-grey\")\n",
        "                    price = price_tag.get_text(strip=True) if price_tag else None\n",
        "\n",
        "                    # Specs (year, mileage, fuel, engine, transmission)\n",
        "                    specs_ul = listing.find(\"ul\", class_=\"list-unstyled search-vehicle-info-2 fs13\")\n",
        "                    specs = specs_ul.find_all(\"li\") if specs_ul else []\n",
        "\n",
        "                    year = specs[0].get_text(strip=True) if len(specs) > 0 else None\n",
        "                    mileage = specs[1].get_text(strip=True) if len(specs) > 1 else None\n",
        "                    fuel = specs[2].get_text(strip=True) if len(specs) > 2 else None\n",
        "                    engine = specs[3].get_text(strip=True) if len(specs) > 3 else None\n",
        "                    transmission = specs[4].get_text(strip=True) if len(specs) > 4 else None\n",
        "\n",
        "                    page_data.append({\n",
        "                        \"Title\": title,\n",
        "                        \"Price\": price,\n",
        "                        \"Year\": year,\n",
        "                        \"Mileage\": mileage,\n",
        "                        \"Fuel\": fuel,\n",
        "                        \"Engine\": engine,\n",
        "                        \"Transmission\": transmission\n",
        "                    })\n",
        "                except:\n",
        "                    continue\n",
        "            return page_data\n",
        "\n",
        "        except Exception as e:\n",
        "            wait = backoff * (2 ** attempt) + random.uniform(0, 0.5)  # jitter\n",
        "            print(f\"⚠️ Page {page_num} failed (attempt {attempt+1}/{retries}): {e}, retrying in {wait:.1f}s\")\n",
        "            time.sleep(wait)\n",
        "\n",
        "    print(f\"❌ Skipped page {page_num} after {retries} failed attempts\")\n",
        "    return []\n",
        "\n",
        "\n",
        "def scrape_all(total_pages=2590, workers=20):\n",
        "    \"\"\"\n",
        "    Scrape all pages in parallel using threads + retries\n",
        "    \"\"\"\n",
        "    all_data = []\n",
        "    with ThreadPoolExecutor(max_workers=workers) as executor:\n",
        "        futures = {executor.submit(scrape_page, page): page for page in range(1, total_pages+1)}\n",
        "\n",
        "        for future in tqdm(as_completed(futures), total=total_pages, desc=\"Scraping\"):\n",
        "            all_data.extend(future.result())\n",
        "\n",
        "    return pd.DataFrame(all_data)\n",
        "\n",
        "\n",
        "# Run in Colab\n",
        "if __name__ == \"__main__\":\n",
        "    df = scrape_all(total_pages=2591, workers=10)  # adjust workers if blocked\n",
        "    print(df.head())\n",
        "    df.to_csv(\"pakwheels_cars.csv\", index=False)\n",
        "    print(\"✅ Data saved to pakwheels_cars.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUOUASUKlXEv",
        "outputId": "10bbc9d3-464c-42a9-ce5e-b86faaebc185"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scraping: 100%|██████████| 2591/2591 [13:09<00:00,  3.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               Title          Price  Year  \\\n",
            "0  Porsche Cayenne  2016 S E-Hybrid Platinum Edition  PKR 2.35crore  2016   \n",
            "1                       Proton X70  2022 Premium FWD     PKR 70lacs  2022   \n",
            "2                             FAW X-PV  2014 Dual AC      PKR 7lacs  2014   \n",
            "3                         Honda N Wgn  2023 G Turbo      PKR 40lacs  2023   \n",
            "4                           Suzuki Wagon R  2017 VXR   PKR 17.5lacs  2017   \n",
            "\n",
            "      Mileage    Fuel   Engine Transmission  \n",
            "0   75,943 km  Hybrid  3000 cc    Automatic  \n",
            "1   12,319 km  Petrol  1500 cc    Automatic  \n",
            "2  331,849 km  Petrol  1000 cc       Manual  \n",
            "3   25,762 km  Petrol   660 cc    Automatic  \n",
            "4  147,219 km  Petrol  1000 cc       Manual  \n",
            "✅ Data saved to pakwheels_cars.csv\n"
          ]
        }
      ]
    }
  ]
}